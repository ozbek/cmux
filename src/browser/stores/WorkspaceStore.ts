import assert from "@/common/utils/assert";
import type { MuxMessage, DisplayedMessage, QueuedMessage } from "@/common/types/message";
import type { FrontendWorkspaceMetadata } from "@/common/types/workspace";
import type { WorkspaceChatMessage, WorkspaceStatsSnapshot } from "@/common/orpc/types";
import type { RouterClient } from "@orpc/server";
import type { AppRouter } from "@/node/orpc/router";
import type { TodoItem } from "@/common/types/tools";
import { StreamingMessageAggregator } from "@/browser/utils/messages/StreamingMessageAggregator";
import { updatePersistedState } from "@/browser/hooks/usePersistedState";
import { getRetryStateKey } from "@/common/constants/storage";
import { BASH_TRUNCATE_MAX_TOTAL_BYTES } from "@/common/constants/toolLimits";
import { CUSTOM_EVENTS, createCustomEvent } from "@/common/constants/events";
import { useSyncExternalStore } from "react";
import {
  isCaughtUpMessage,
  isStreamError,
  isDeleteMessage,
  isBashOutputEvent,
  isMuxMessage,
  isQueuedMessageChanged,
  isRestoreToInput,
} from "@/common/orpc/types";
import type { StreamEndEvent, StreamAbortEvent } from "@/common/types/stream";
import { MapStore } from "./MapStore";
import { createDisplayUsage } from "@/common/utils/tokens/displayUsage";
import { WorkspaceConsumerManager } from "./WorkspaceConsumerManager";
import type { ChatUsageDisplay } from "@/common/utils/tokens/usageAggregator";
import { sumUsageHistory } from "@/common/utils/tokens/usageAggregator";
import type { TokenConsumer } from "@/common/types/chatStats";
import { normalizeGatewayModel } from "@/common/utils/ai/models";
import type { z } from "zod";
import type { SessionUsageFileSchema } from "@/common/orpc/schemas/chatStats";
import type { LanguageModelV2Usage } from "@ai-sdk/provider";
import { createFreshRetryState } from "@/browser/utils/messages/retryState";
import {
  appendLiveBashOutputChunk,
  type LiveBashOutputInternal,
  type LiveBashOutputView,
} from "@/browser/utils/messages/liveBashOutputBuffer";
import { trackStreamCompleted } from "@/common/telemetry";

export interface WorkspaceState {
  name: string; // User-facing workspace name (e.g., "feature-branch")
  messages: DisplayedMessage[];
  queuedMessage: QueuedMessage | null;
  canInterrupt: boolean;
  isCompacting: boolean;
  awaitingUserQuestion: boolean;
  loading: boolean;
  muxMessages: MuxMessage[];
  currentModel: string | null;
  recencyTimestamp: number | null;
  todos: TodoItem[];
  agentStatus: { emoji: string; message: string; url?: string } | undefined;
  pendingStreamStartTime: number | null;
  // Live streaming stats (updated on each stream-delta)
  streamingTokenCount: number | undefined;
  streamingTPS: number | undefined;
}

/**
 * Timing statistics for streaming sessions (active or completed).
 * When isActive=true, endTime is null and elapsed time should be computed live.
 * When isActive=false, endTime contains the completion timestamp.
 */
export interface StreamTimingStats {
  /** When the stream started (Date.now()) */
  startTime: number;
  /** When the stream ended, null if still active */
  endTime: number | null;
  /** When first content token arrived, null if still waiting */
  firstTokenTime: number | null;
  /** Accumulated tool execution time in ms */
  toolExecutionMs: number;
  /** Whether this is an active stream (true) or completed (false) */
  isActive: boolean;
  /** Model used for this stream */
  model: string;
  /** Output tokens (excludes reasoning/thinking tokens) - only available for completed streams */
  outputTokens?: number;
  /** Reasoning/thinking tokens - only available for completed streams */
  reasoningTokens?: number;
  /** Streaming duration in ms (first token to end) - only available for completed streams */
  streamingMs?: number;
  /** Live token count during streaming - only available for active streams */
  liveTokenCount?: number;
  /** Live tokens-per-second during streaming - only available for active streams */
  liveTPS?: number;
  /** Mode (plan/exec) in which this stream occurred */
  mode?: string;
}

/** Per-model timing statistics */
export interface ModelTimingStats {
  /** Total time spent in responses for this model */
  totalDurationMs: number;
  /** Total time spent executing tools for this model */
  totalToolExecutionMs: number;
  /** Total time spent streaming tokens (excludes TTFT) - for accurate tokens/sec */
  totalStreamingMs: number;
  /** Average time to first token for this model */
  averageTtftMs: number | null;
  /** Number of completed responses for this model */
  responseCount: number;
  /** Total output tokens generated by this model (excludes reasoning/thinking tokens) */
  totalOutputTokens: number;
  /** Total reasoning/thinking tokens generated by this model */
  totalReasoningTokens: number;
  /** Mode extracted from composite key (undefined for old data without mode) */
  mode?: string;
}

/**
 * Aggregate timing statistics across all completed streams in a session.
 */
export interface SessionTimingStats {
  /** Total time spent in all responses */
  totalDurationMs: number;
  /** Total time spent executing tools */
  totalToolExecutionMs: number;
  /** Total time spent streaming tokens (excludes TTFT) - for accurate tokens/sec */
  totalStreamingMs: number;
  /** Average time to first token (null if no responses had TTFT) */
  averageTtftMs: number | null;
  /** Number of completed responses */
  responseCount: number;
  /** Total output tokens generated across all models (excludes reasoning/thinking tokens) */
  totalOutputTokens: number;
  /** Total reasoning/thinking tokens generated across all models */
  totalReasoningTokens: number;
  /** Per-model timing breakdown */

  byModel: Record<string, ModelTimingStats>;
}

/**
 * Subset of WorkspaceState needed for sidebar display.
 * Subscribing to only these fields prevents re-renders when messages update.
 */
function shallowEqual(a: object | null | undefined, b: object | null | undefined): boolean {
  if (a === b) {
    return true;
  }
  if (!a || !b) {
    return false;
  }

  const aRecord = a as Record<string, unknown>;
  const bRecord = b as Record<string, unknown>;

  const aKeys = Object.keys(aRecord);
  const bKeys = Object.keys(bRecord);
  if (aKeys.length !== bKeys.length) {
    return false;
  }

  for (const key of aKeys) {
    if (!Object.prototype.hasOwnProperty.call(bRecord, key)) {
      return false;
    }
    if (!Object.is(aRecord[key], bRecord[key])) {
      return false;
    }
  }

  return true;
}

export interface WorkspaceSidebarState {
  canInterrupt: boolean;
  awaitingUserQuestion: boolean;
  currentModel: string | null;
  recencyTimestamp: number | null;
  agentStatus: { emoji: string; message: string; url?: string } | undefined;
  /** Timing stats for current/last stream */
  timingStats: StreamTimingStats | null;
  /** Aggregate timing stats across all responses in session */
  sessionStats: SessionTimingStats | null;
}

/**
 * Derived state values stored in the derived MapStore.
 * Currently only recency timestamps for workspace sorting.
 */
type DerivedState = Record<string, number>;

/**
 * Usage metadata extracted from API responses (no tokenization).
 * Updates instantly when usage metadata arrives.
 *
 * For multi-step tool calls, cost and context usage differ:
 * - sessionTotal: Pre-computed sum of all models from session-usage.json
 * - lastRequest: Last completed request (persisted for app restart)
 * - lastContextUsage: Last step's usage for context window display (inputTokens = actual context size)
 */
export interface WorkspaceUsageState {
  /** Pre-computed session total (sum of all models) */
  sessionTotal?: ChatUsageDisplay;
  /** Last completed request (persisted) */
  lastRequest?: {
    model: string;
    usage: ChatUsageDisplay;
    timestamp: number;
  };
  /** Last message's context usage (last step only, for context window display) */
  lastContextUsage?: ChatUsageDisplay;
  totalTokens: number;
  /** Live context usage during streaming (last step's inputTokens = current context window) */
  liveUsage?: ChatUsageDisplay;
  /** Live cost usage during streaming (cumulative across all steps) */
  liveCostUsage?: ChatUsageDisplay;
}

/**
 * Consumer breakdown requiring tokenization (lazy calculation).
 * Updates after async Web Worker calculation completes.
 */
export interface WorkspaceConsumersState {
  consumers: TokenConsumer[];
  tokenizerName: string;
  totalTokens: number; // Total from tokenization (may differ from usage totalTokens)
  isCalculating: boolean;
}

interface WorkspaceChatTransientState {
  caughtUp: boolean;
  historicalMessages: MuxMessage[];
  pendingStreamEvents: WorkspaceChatMessage[];
  replayingHistory: boolean;
  queuedMessage: QueuedMessage | null;
  liveBashOutput: Map<string, LiveBashOutputInternal>;
}

function createInitialChatTransientState(): WorkspaceChatTransientState {
  return {
    caughtUp: false,
    historicalMessages: [],
    pendingStreamEvents: [],
    replayingHistory: false,
    queuedMessage: null,
    liveBashOutput: new Map(),
  };
}

const ON_CHAT_RETRY_BASE_MS = 250;
const ON_CHAT_RETRY_MAX_MS = 5000;

interface ValidationIssue {
  path?: Array<string | number>;
  message?: string;
}

type IteratorValidationFailedError = Error & {
  code: "EVENT_ITERATOR_VALIDATION_FAILED";
  cause?: {
    issues?: ValidationIssue[];
    data?: unknown;
  };
};

function isIteratorValidationFailed(error: unknown): error is IteratorValidationFailedError {
  return (
    error instanceof Error &&
    (error as { code?: unknown }).code === "EVENT_ITERATOR_VALIDATION_FAILED"
  );
}

/**
 * Extract a human-readable summary from an iterator validation error.
 * ORPC wraps Zod issues in error.cause with { issues: [...], data: ... }
 */
function formatValidationError(error: IteratorValidationFailedError): string {
  const cause = error.cause;
  if (!cause) {
    return "Unknown validation error (no cause)";
  }

  const issues = cause.issues ?? [];
  if (issues.length === 0) {
    return `Unknown validation error (no issues). Data: ${JSON.stringify(cause.data)}`;
  }

  // Format issues like: "type: Invalid discriminator value" or "metadata.usage.inputTokens: Expected number"
  const issuesSummary = issues
    .slice(0, 3) // Limit to first 3 issues
    .map((issue) => {
      const path = issue.path?.join(".") ?? "(root)";
      const message = issue.message ?? "Unknown issue";
      return `${path}: ${message}`;
    })
    .join("; ");

  const moreCount = issues.length > 3 ? ` (+${issues.length - 3} more)` : "";

  // Include the event type if available
  const data = cause.data as { type?: string } | undefined;
  const eventType = data?.type ? ` [event: ${data.type}]` : "";

  return `${issuesSummary}${moreCount}${eventType}`;
}

function calculateOnChatBackoffMs(attempt: number): number {
  return Math.min(ON_CHAT_RETRY_BASE_MS * 2 ** attempt, ON_CHAT_RETRY_MAX_MS);
}

/**
 * External store for workspace aggregators and streaming state.
 *
 * This store lives outside React's lifecycle and manages all workspace
 * message aggregation and IPC subscriptions. Components subscribe to
 * specific workspaces via useSyncExternalStore, ensuring only relevant
 * components re-render when workspace state changes.
 */
export class WorkspaceStore {
  // Per-workspace state (lazy computed on get)
  private states = new MapStore<string, WorkspaceState>();

  // Derived aggregate state (computed from multiple workspaces)
  private derived = new MapStore<string, DerivedState>();

  // Usage and consumer stores (two-store approach for CostsTab optimization)
  private usageStore = new MapStore<string, WorkspaceUsageState>();
  private client: RouterClient<AppRouter> | null = null;
  private consumersStore = new MapStore<string, WorkspaceConsumersState>();

  // Manager for consumer calculations (debouncing, caching, lazy loading)
  // Architecture: WorkspaceStore orchestrates (decides when), manager executes (performs calculations)
  // Dual-cache: consumersStore (MapStore) handles subscriptions, manager owns data cache
  private readonly consumerManager: WorkspaceConsumerManager;

  // Supporting data structures
  private aggregators = new Map<string, StreamingMessageAggregator>();
  private ipcUnsubscribers = new Map<string, () => void>();

  // Per-workspace ephemeral chat state (buffering, queued message, live bash output, etc.)
  private chatTransientState = new Map<string, WorkspaceChatTransientState>();

  private workspaceMetadata = new Map<string, FrontendWorkspaceMetadata>(); // Store metadata for name lookup

  // Workspace timing stats snapshots (from workspace.stats.subscribe)
  private statsEnabled = false;
  private workspaceStats = new Map<string, WorkspaceStatsSnapshot>();
  private statsStore = new MapStore<string, WorkspaceStatsSnapshot | null>();
  private statsUnsubscribers = new Map<string, () => void>();
  // Cumulative session usage (from session-usage.json)

  private sessionUsage = new Map<string, z.infer<typeof SessionUsageFileSchema>>();

  // Idle compaction notification callbacks (called when backend signals idle compaction needed)
  private idleCompactionCallbacks = new Set<(workspaceId: string) => void>();

  // Tracks when a file-modifying tool (file_edit_*, bash) last completed per workspace.
  // ReviewPanel subscribes to trigger diff refresh. Two structures:
  // - timestamps: actual Date.now() values for cache invalidation checks
  // - subscriptions: MapStore for per-workspace subscription support
  private fileModifyingToolMs = new Map<string, number>();
  private fileModifyingToolSubs = new MapStore<string, void>();

  // Idle callback handles for high-frequency delta events to reduce re-renders during streaming.
  // Data is always updated immediately in the aggregator; only UI notification is scheduled.
  // Using requestIdleCallback adapts to actual CPU availability rather than a fixed timer.
  private deltaIdleHandles = new Map<string, number>();

  /**
   * Map of event types to their handlers. This is the single source of truth for:
   * 1. Which events should be buffered during replay (the keys)
   * 2. How to process those events (the values)
   *
   * By keeping check and processing in one place, we make it structurally impossible
   * to buffer an event type without having a handler for it.
   */
  private readonly bufferedEventHandlers: Record<
    string,
    (
      workspaceId: string,
      aggregator: StreamingMessageAggregator,
      data: WorkspaceChatMessage
    ) => void
  > = {
    "stream-start": (workspaceId, aggregator, data) => {
      aggregator.handleStreamStart(data as never);
      if (this.onModelUsed) {
        this.onModelUsed((data as { model: string }).model);
      }
      // Don't reset retry state here - stream might still fail after starting
      // Retry state will be reset on stream-end (successful completion)
      this.states.bump(workspaceId);
      // Bump usage store so liveUsage is recomputed with new activeStreamId
      this.usageStore.bump(workspaceId);
    },
    "stream-delta": (workspaceId, aggregator, data) => {
      aggregator.handleStreamDelta(data as never);
      this.scheduleIdleStateBump(workspaceId);
    },
    "stream-end": (workspaceId, aggregator, data) => {
      const streamEndData = data as StreamEndEvent;
      aggregator.handleStreamEnd(streamEndData as never);
      aggregator.clearTokenState(streamEndData.messageId);

      // Track stream completion telemetry
      this.trackStreamCompletedTelemetry(streamEndData, false);

      // Reset retry state on successful stream completion
      updatePersistedState(getRetryStateKey(workspaceId), createFreshRetryState());

      // Update local session usage (mirrors backend's addUsage)
      const model = streamEndData.metadata?.model;
      const rawUsage = streamEndData.metadata?.usage;
      const providerMetadata = streamEndData.metadata?.providerMetadata;
      if (model && rawUsage) {
        const usage = createDisplayUsage(rawUsage, model, providerMetadata);
        if (usage) {
          const normalizedModel = normalizeGatewayModel(model);
          const current = this.sessionUsage.get(workspaceId) ?? {
            byModel: {},
            version: 1 as const,
          };
          const existing = current.byModel[normalizedModel];
          // CRITICAL: Accumulate, don't overwrite (same logic as backend)
          current.byModel[normalizedModel] = existing ? sumUsageHistory([existing, usage])! : usage;
          current.lastRequest = { model: normalizedModel, usage, timestamp: Date.now() };
          this.sessionUsage.set(workspaceId, current);
        }
      }

      // Flush any pending debounced bump before final bump to avoid double-bump
      this.cancelPendingIdleBump(workspaceId);
      this.states.bump(workspaceId);
      this.checkAndBumpRecencyIfChanged();
      this.finalizeUsageStats(workspaceId, streamEndData.metadata);
    },
    "stream-abort": (workspaceId, aggregator, data) => {
      const streamAbortData = data as StreamAbortEvent;
      aggregator.clearTokenState(streamAbortData.messageId);
      aggregator.handleStreamAbort(streamAbortData as never);

      // Track stream interruption telemetry (get model from aggregator)
      const model = aggregator.getCurrentModel();
      if (model) {
        this.trackStreamCompletedTelemetry(
          {
            metadata: {
              model,
              usage: streamAbortData.metadata?.usage,
              duration: streamAbortData.metadata?.duration,
            },
          },
          true
        );
      }

      // Flush any pending debounced bump before final bump to avoid double-bump
      this.cancelPendingIdleBump(workspaceId);
      this.states.bump(workspaceId);
      this.dispatchResumeCheck(workspaceId);
      this.finalizeUsageStats(workspaceId, streamAbortData.metadata);
    },
    "tool-call-start": (workspaceId, aggregator, data) => {
      aggregator.handleToolCallStart(data as never);
      this.states.bump(workspaceId);
    },
    "tool-call-delta": (workspaceId, aggregator, data) => {
      aggregator.handleToolCallDelta(data as never);
      this.scheduleIdleStateBump(workspaceId);
    },
    "tool-call-end": (workspaceId, aggregator, data) => {
      const toolCallEnd = data as Extract<WorkspaceChatMessage, { type: "tool-call-end" }>;

      // Cleanup live bash output once the real tool result contains output.
      // If output is missing (e.g. tmpfile overflow), keep the tail buffer so the UI still shows something.
      if (toolCallEnd.toolName === "bash") {
        const output = (toolCallEnd.result as { output?: unknown } | undefined)?.output;
        if (typeof output === "string") {
          const transient = this.chatTransientState.get(workspaceId);
          transient?.liveBashOutput.delete(toolCallEnd.toolCallId);
        }
      }

      aggregator.handleToolCallEnd(data as never);
      this.states.bump(workspaceId);
      this.consumerManager.scheduleCalculation(workspaceId, aggregator);

      // Track file-modifying tools for ReviewPanel diff refresh
      if (toolCallEnd.toolName.startsWith("file_edit_") || toolCallEnd.toolName === "bash") {
        this.fileModifyingToolMs.set(workspaceId, Date.now());
        this.fileModifyingToolSubs.bump(workspaceId);
      }
    },
    "reasoning-delta": (workspaceId, aggregator, data) => {
      aggregator.handleReasoningDelta(data as never);
      this.scheduleIdleStateBump(workspaceId);
    },
    "reasoning-end": (workspaceId, aggregator, data) => {
      aggregator.handleReasoningEnd(data as never);
      this.states.bump(workspaceId);
    },
    "session-usage-delta": (workspaceId, _aggregator, data) => {
      const usageDelta = data as Extract<WorkspaceChatMessage, { type: "session-usage-delta" }>;

      const current = this.sessionUsage.get(workspaceId) ?? {
        byModel: {},
        version: 1 as const,
      };

      for (const [model, usage] of Object.entries(usageDelta.byModelDelta)) {
        const existing = current.byModel[model];
        current.byModel[model] = existing ? sumUsageHistory([existing, usage])! : usage;
      }

      this.sessionUsage.set(workspaceId, current);
      this.usageStore.bump(workspaceId);
    },
    "usage-delta": (workspaceId, aggregator, data) => {
      aggregator.handleUsageDelta(data as never);
      this.usageStore.bump(workspaceId);
    },
    "init-start": (workspaceId, aggregator, data) => {
      aggregator.handleMessage(data);
      this.states.bump(workspaceId);
    },
    "init-output": (workspaceId, aggregator, data) => {
      aggregator.handleMessage(data);
      this.states.bump(workspaceId);
    },
    "init-end": (workspaceId, aggregator, data) => {
      aggregator.handleMessage(data);
      this.states.bump(workspaceId);
    },
    "queued-message-changed": (workspaceId, _aggregator, data) => {
      if (!isQueuedMessageChanged(data)) return;

      // Create QueuedMessage once here instead of on every render
      // Use displayText which handles slash commands (shows /compact instead of expanded prompt)
      // Show queued message if there's text OR images OR reviews (support review-only queued messages)
      const hasContent =
        data.queuedMessages.length > 0 ||
        (data.imageParts?.length ?? 0) > 0 ||
        (data.reviews?.length ?? 0) > 0;
      const queuedMessage: QueuedMessage | null = hasContent
        ? {
            id: `queued-${workspaceId}`,
            content: data.displayText,
            imageParts: data.imageParts,
            reviews: data.reviews,
          }
        : null;

      this.assertChatTransientState(workspaceId).queuedMessage = queuedMessage;
      this.states.bump(workspaceId);
    },
    "restore-to-input": (workspaceId, _aggregator, data) => {
      if (!isRestoreToInput(data)) return;

      // Use INSERT_TO_CHAT_INPUT event with mode="replace"
      window.dispatchEvent(
        createCustomEvent(CUSTOM_EVENTS.INSERT_TO_CHAT_INPUT, {
          text: data.text,
          mode: "replace",
          imageParts: data.imageParts,
        })
      );
    },
  };

  // Cache of last known recency per workspace (for change detection)
  private recencyCache = new Map<string, number | null>();

  // Store workspace metadata for aggregator creation (ensures createdAt never lost)
  private workspaceCreatedAt = new Map<string, string>();

  // Track previous sidebar state per workspace (to prevent unnecessary bumps)
  private previousSidebarValues = new Map<string, WorkspaceSidebarState>();

  // Track model usage (optional integration point for model bookkeeping)
  private readonly onModelUsed?: (model: string) => void;

  constructor(onModelUsed?: (model: string) => void) {
    this.onModelUsed = onModelUsed;

    // Initialize consumer calculation manager
    this.consumerManager = new WorkspaceConsumerManager((workspaceId) => {
      this.consumersStore.bump(workspaceId);
    });

    // Note: We DON'T auto-check recency on every state bump.
    // Instead, checkAndBumpRecencyIfChanged() is called explicitly after
    // message completion events (not on deltas) to prevent App.tsx re-renders.
  }

  setStatsEnabled(enabled: boolean): void {
    if (this.statsEnabled === enabled) {
      return;
    }

    this.statsEnabled = enabled;

    if (!enabled) {
      for (const unsubscribe of this.statsUnsubscribers.values()) {
        unsubscribe();
      }
      this.statsUnsubscribers.clear();
      this.workspaceStats.clear();

      for (const workspaceId of this.ipcUnsubscribers.keys()) {
        this.statsStore.bump(workspaceId);
      }
      return;
    }

    // Enable subscriptions for already-added workspaces.
    for (const workspaceId of this.ipcUnsubscribers.keys()) {
      this.subscribeToStats(workspaceId);
    }
  }
  setClient(client: RouterClient<AppRouter>) {
    this.client = client;
  }

  /**
   * Dispatch resume check event for a workspace.
   * Triggers useResumeManager to check if interrupted stream can be resumed.
   */
  private dispatchResumeCheck(workspaceId: string): void {
    window.dispatchEvent(createCustomEvent(CUSTOM_EVENTS.RESUME_CHECK_REQUESTED, { workspaceId }));
  }

  /**
   * Schedule a state bump during browser idle time.
   * Instead of updating UI on every delta, wait until the browser has spare capacity.
   * This adapts to actual CPU availability - fast machines update more frequently,
   * slow machines naturally throttle without dropping data.
   *
   * Data is always updated immediately in the aggregator - only UI notification is deferred.
   */
  private scheduleIdleStateBump(workspaceId: string): void {
    // Skip if already scheduled
    if (this.deltaIdleHandles.has(workspaceId)) {
      return;
    }

    // requestIdleCallback is not available in some environments (e.g. Node-based unit tests).
    // Fall back to a regular timeout so we still throttle bumps.
    if (typeof requestIdleCallback !== "function") {
      const handle = setTimeout(() => {
        this.deltaIdleHandles.delete(workspaceId);
        this.states.bump(workspaceId);
      }, 0);

      this.deltaIdleHandles.set(workspaceId, handle as unknown as number);
      return;
    }

    const handle = requestIdleCallback(
      () => {
        this.deltaIdleHandles.delete(workspaceId);
        this.states.bump(workspaceId);
      },
      { timeout: 100 } // Force update within 100ms even if browser stays busy
    );

    this.deltaIdleHandles.set(workspaceId, handle);
  }

  /**
   * Subscribe to backend timing stats snapshots for a workspace.
   */

  private subscribeToStats(workspaceId: string): void {
    if (!this.client || !this.statsEnabled) {
      return;
    }

    // Skip if already subscribed
    if (this.statsUnsubscribers.has(workspaceId)) {
      return;
    }

    const controller = new AbortController();
    const { signal } = controller;

    (async () => {
      try {
        const iterator = await this.client!.workspace.stats.subscribe({ workspaceId }, { signal });

        for await (const snapshot of iterator) {
          if (signal.aborted) break;
          queueMicrotask(() => {
            this.workspaceStats.set(workspaceId, snapshot);
            this.statsStore.bump(workspaceId);
          });
        }
      } catch (error) {
        if (signal.aborted) return;
        console.warn(`[WorkspaceStore] Error in stats subscription for ${workspaceId}:`, error);
      }
    })();

    this.statsUnsubscribers.set(workspaceId, () => controller.abort());
  }

  /**
   * Cancel any pending idle state bump for a workspace.
   * Used when immediate state visibility is needed (e.g., stream-end).
   * Just cancels the callback - the caller will bump() immediately after.
   */
  private cancelPendingIdleBump(workspaceId: string): void {
    const handle = this.deltaIdleHandles.get(workspaceId);
    if (handle) {
      if (typeof cancelIdleCallback === "function") {
        cancelIdleCallback(handle);
      } else {
        clearTimeout(handle as unknown as number);
      }
      this.deltaIdleHandles.delete(workspaceId);
    }
  }

  /**
   * Track stream completion telemetry
   */
  private trackStreamCompletedTelemetry(
    data: {
      metadata: {
        model: string;
        usage?: { outputTokens?: number };
        duration?: number;
      };
    },
    wasInterrupted: boolean
  ): void {
    const { metadata } = data;
    const durationSecs = metadata.duration ? metadata.duration / 1000 : 0;
    const outputTokens = metadata.usage?.outputTokens ?? 0;

    // trackStreamCompleted handles rounding internally
    trackStreamCompleted(metadata.model, wasInterrupted, durationSecs, outputTokens);
  }

  /**
   * Check if any workspace's recency changed and bump global recency if so.
   * Uses cached recency values from aggregators for O(1) comparison per workspace.
   */
  private checkAndBumpRecencyIfChanged(): void {
    let recencyChanged = false;

    for (const workspaceId of this.aggregators.keys()) {
      const aggregator = this.aggregators.get(workspaceId)!;
      const currentRecency = aggregator.getRecencyTimestamp();
      const cachedRecency = this.recencyCache.get(workspaceId);

      if (currentRecency !== cachedRecency) {
        this.recencyCache.set(workspaceId, currentRecency);
        recencyChanged = true;
      }
    }

    if (recencyChanged) {
      this.derived.bump("recency");
    }
  }

  private cleanupStaleLiveBashOutput(
    workspaceId: string,
    aggregator: StreamingMessageAggregator
  ): void {
    const perWorkspace = this.chatTransientState.get(workspaceId)?.liveBashOutput;
    if (!perWorkspace || perWorkspace.size === 0) return;

    const activeToolCallIds = new Set<string>();
    for (const msg of aggregator.getDisplayedMessages()) {
      if (msg.type === "tool" && msg.toolName === "bash") {
        activeToolCallIds.add(msg.toolCallId);
      }
    }

    for (const toolCallId of Array.from(perWorkspace.keys())) {
      if (!activeToolCallIds.has(toolCallId)) {
        perWorkspace.delete(toolCallId);
      }
    }
  }

  /**
   * Subscribe to store changes (any workspace).
   * Delegates to MapStore's subscribeAny.
   */
  subscribe = this.states.subscribeAny;

  /**
   * Subscribe to derived state changes (recency, etc.).
   * Use for hooks that depend on derived.bump() rather than states.bump().
   */
  subscribeDerived = this.derived.subscribeAny;

  /**
   * Subscribe to changes for a specific workspace.
   * Only notified when this workspace's state changes.
   */
  subscribeKey = (workspaceId: string, listener: () => void) => {
    return this.states.subscribeKey(workspaceId, listener);
  };

  getBashToolLiveOutput(workspaceId: string, toolCallId: string): LiveBashOutputView | null {
    const state = this.chatTransientState.get(workspaceId)?.liveBashOutput.get(toolCallId);

    // Important: return the stored object reference so useSyncExternalStore sees a stable snapshot.
    // (Returning a fresh object every call can trigger an infinite re-render loop.)
    return state ?? null;
  }

  /**
   * Assert that workspace exists and return its aggregator.
   * Centralized assertion for all workspace access methods.
   */
  private assertGet(workspaceId: string): StreamingMessageAggregator {
    const aggregator = this.aggregators.get(workspaceId);
    assert(aggregator, `Workspace ${workspaceId} not found - must call addWorkspace() first`);
    return aggregator;
  }

  private assertChatTransientState(workspaceId: string): WorkspaceChatTransientState {
    const state = this.chatTransientState.get(workspaceId);
    assert(state, `Workspace ${workspaceId} not found - must call addWorkspace() first`);
    return state;
  }

  /**
   * Get state for a specific workspace.
   * Lazy computation - only runs when version changes.
   *
   * REQUIRES: Workspace must have been added via addWorkspace() first.
   */
  getWorkspaceState(workspaceId: string): WorkspaceState {
    return this.states.get(workspaceId, () => {
      const aggregator = this.assertGet(workspaceId);

      const hasMessages = aggregator.hasMessages();
      const transient = this.assertChatTransientState(workspaceId);
      const activeStreams = aggregator.getActiveStreams();
      const messages = aggregator.getAllMessages();
      const metadata = this.workspaceMetadata.get(workspaceId);

      // Live streaming stats
      const activeStreamMessageId = aggregator.getActiveStreamMessageId();
      const streamingTokenCount = activeStreamMessageId
        ? aggregator.getStreamingTokenCount(activeStreamMessageId)
        : undefined;
      const streamingTPS = activeStreamMessageId
        ? aggregator.getStreamingTPS(activeStreamMessageId)
        : undefined;

      return {
        name: metadata?.name ?? workspaceId, // Fall back to ID if metadata missing
        messages: aggregator.getDisplayedMessages(),
        queuedMessage: transient.queuedMessage,
        canInterrupt: activeStreams.length > 0,
        isCompacting: aggregator.isCompacting(),
        awaitingUserQuestion: aggregator.hasAwaitingUserQuestion(),
        loading: !hasMessages && !transient.caughtUp,
        muxMessages: messages,
        currentModel: aggregator.getCurrentModel() ?? null,
        recencyTimestamp: aggregator.getRecencyTimestamp(),
        todos: aggregator.getCurrentTodos(),
        agentStatus: aggregator.getAgentStatus(),
        pendingStreamStartTime: aggregator.getPendingStreamStartTime(),
        streamingTokenCount,
        streamingTPS,
      };
    });
  }

  // Cache sidebar state objects to return stable references
  private sidebarStateCache = new Map<string, WorkspaceSidebarState>();
  // Map from workspaceId -> the WorkspaceState reference used to compute sidebarStateCache.
  // React's useSyncExternalStore may call getSnapshot() multiple times per render; this
  // ensures getWorkspaceSidebarState() returns a referentially stable snapshot for a given
  // MapStore version even when timingStats would otherwise change via Date.now().
  private sidebarStateSourceState = new Map<string, WorkspaceState>();

  /**
   * Get sidebar state for a workspace (subset of full state).
   * Returns cached reference if values haven't changed.
   * This is critical for useSyncExternalStore - must return stable references.
   */
  getWorkspaceSidebarState(workspaceId: string): WorkspaceSidebarState {
    const fullState = this.getWorkspaceState(workspaceId);

    const cached = this.sidebarStateCache.get(workspaceId);
    if (cached && this.sidebarStateSourceState.get(workspaceId) === fullState) {
      return cached;
    }

    const aggregator = this.aggregators.get(workspaceId);

    // Get timing stats: prefer active stream, fall back to last completed
    let timingStats: StreamTimingStats | null = null;
    const activeStats = aggregator?.getActiveStreamTimingStats();
    if (activeStats) {
      timingStats = {
        ...activeStats,
        endTime: null,
        isActive: true,
      };
    } else {
      const completedStats = aggregator?.getLastCompletedStreamStats();
      if (completedStats) {
        timingStats = {
          ...completedStats,
          isActive: false,
        };
      }
    }

    // Get session-level aggregate stats
    const sessionStats = aggregator?.getSessionTimingStats() ?? null;

    // Return cached if values match.
    if (
      cached &&
      cached.canInterrupt === fullState.canInterrupt &&
      cached.awaitingUserQuestion === fullState.awaitingUserQuestion &&
      cached.currentModel === fullState.currentModel &&
      cached.recencyTimestamp === fullState.recencyTimestamp &&
      cached.agentStatus === fullState.agentStatus &&
      // Timing stats: compare all fields for equality
      shallowEqual(cached.timingStats, timingStats) &&
      // Session stats: compare key fields
      (cached.sessionStats === sessionStats ||
        (cached.sessionStats?.totalDurationMs === sessionStats?.totalDurationMs &&
          cached.sessionStats?.responseCount === sessionStats?.responseCount))
    ) {
      // Even if we re-use the cached object, mark it as derived from the current
      // WorkspaceState so repeated getSnapshot() reads during this render are stable.
      this.sidebarStateSourceState.set(workspaceId, fullState);
      return cached;
    }

    // Create and cache new state
    const newState: WorkspaceSidebarState = {
      canInterrupt: fullState.canInterrupt,
      awaitingUserQuestion: fullState.awaitingUserQuestion,
      currentModel: fullState.currentModel,
      recencyTimestamp: fullState.recencyTimestamp,
      agentStatus: fullState.agentStatus,
      timingStats,
      sessionStats,
    };
    this.sidebarStateCache.set(workspaceId, newState);
    this.sidebarStateSourceState.set(workspaceId, fullState);
    return newState;
  }

  /**
   * Clear timing stats for a workspace.
   *
   * - Clears backend-persisted timing file (session-timing.json) when available.
   * - Clears in-memory timing derived from StreamingMessageAggregator.
   */
  clearTimingStats(workspaceId: string): void {
    if (this.client && this.statsEnabled) {
      this.client.workspace.stats
        .clear({ workspaceId })
        .then((result) => {
          if (!result.success) {
            console.warn(`Failed to clear timing stats for ${workspaceId}:`, result.error);
            return;
          }

          this.workspaceStats.delete(workspaceId);
          this.statsStore.bump(workspaceId);
        })
        .catch((error) => {
          console.warn(`Failed to clear timing stats for ${workspaceId}:`, error);
        });
    }

    const aggregator = this.aggregators.get(workspaceId);
    if (aggregator) {
      aggregator.clearSessionTimingStats();
      this.states.bump(workspaceId);
    }
  }

  /**
   * Get all workspace states as a Map.
   * Returns a new Map on each call - not cached/reactive.
   * Used by imperative code, not for React subscriptions.
   */
  getAllStates(): Map<string, WorkspaceState> {
    const allStates = new Map<string, WorkspaceState>();
    for (const workspaceId of this.aggregators.keys()) {
      allStates.set(workspaceId, this.getWorkspaceState(workspaceId));
    }
    return allStates;
  }

  /**
   * Get recency timestamps for all workspaces (for sorting in command palette).
   * Derived on-demand from individual workspace states.
   */
  getWorkspaceRecency(): Record<string, number> {
    return this.derived.get("recency", () => {
      const timestamps: Record<string, number> = {};
      for (const workspaceId of this.aggregators.keys()) {
        const state = this.getWorkspaceState(workspaceId);
        if (state.recencyTimestamp !== null) {
          timestamps[workspaceId] = state.recencyTimestamp;
        }
      }
      return timestamps;
    }) as Record<string, number>;
  }

  /**
   * Get aggregator for a workspace (used by components that need direct access).
   * Returns undefined if workspace does not exist.
   */
  getAggregator(workspaceId: string): StreamingMessageAggregator | undefined {
    return this.aggregators.get(workspaceId);
  }

  /**
   * Mark the current active stream as "interrupting" (transient state).
   * Call this before invoking interruptStream so the UI shows "interrupting..."
   * immediately, avoiding a visual flash when the backend confirmation arrives.
   */
  setInterrupting(workspaceId: string): void {
    const aggregator = this.aggregators.get(workspaceId);
    if (aggregator) {
      aggregator.setInterrupting();
      this.states.bump(workspaceId);
    }
  }

  getWorkspaceStatsSnapshot(workspaceId: string): WorkspaceStatsSnapshot | null {
    return this.statsStore.get(workspaceId, () => {
      return this.workspaceStats.get(workspaceId) ?? null;
    });
  }

  /**
   * Bump state for a workspace to trigger React re-renders.
   * Used by addEphemeralMessage for frontend-only messages.
   */
  bumpState(workspaceId: string): void {
    this.states.bump(workspaceId);
  }

  /**
   * Get current TODO list for a workspace.
   * Returns empty array if workspace doesn't exist or has no TODOs.
   */
  getTodos(workspaceId: string): TodoItem[] {
    const aggregator = this.aggregators.get(workspaceId);
    return aggregator ? aggregator.getCurrentTodos() : [];
  }

  /**
   * Extract usage from session-usage.json (no tokenization or message iteration).
   *
   * Returns empty state if workspace doesn't exist (e.g., creation mode).
   */
  getWorkspaceUsage(workspaceId: string): WorkspaceUsageState {
    return this.usageStore.get(workspaceId, () => {
      const aggregator = this.aggregators.get(workspaceId);
      if (!aggregator) {
        return { totalTokens: 0 };
      }

      const model = aggregator.getCurrentModel();
      const sessionData = this.sessionUsage.get(workspaceId);

      // Session total: sum all models from persisted data
      const sessionTotal =
        sessionData && Object.keys(sessionData.byModel).length > 0
          ? sumUsageHistory(Object.values(sessionData.byModel))
          : undefined;

      // Last request from persisted data
      const lastRequest = sessionData?.lastRequest;

      // Calculate total tokens from session total
      const totalTokens = sessionTotal
        ? sessionTotal.input.tokens +
          sessionTotal.cached.tokens +
          sessionTotal.cacheCreate.tokens +
          sessionTotal.output.tokens +
          sessionTotal.reasoning.tokens
        : 0;

      // Get last message's context usage (unchanged from before)
      const messages = aggregator.getAllMessages();
      const lastContextUsage = (() => {
        for (let i = messages.length - 1; i >= 0; i--) {
          const msg = messages[i];
          if (msg.role === "assistant") {
            if (msg.metadata?.compacted) continue;
            const rawUsage = msg.metadata?.contextUsage;
            const providerMeta =
              msg.metadata?.contextProviderMetadata ?? msg.metadata?.providerMetadata;
            if (rawUsage) {
              const msgModel = msg.metadata?.model ?? model ?? "unknown";
              return createDisplayUsage(rawUsage, msgModel, providerMeta);
            }
          }
        }
        return undefined;
      })();

      // Live streaming data (unchanged)
      const activeStreamId = aggregator.getActiveStreamMessageId();
      const rawContextUsage = activeStreamId
        ? aggregator.getActiveStreamUsage(activeStreamId)
        : undefined;
      const rawStepProviderMetadata = activeStreamId
        ? aggregator.getActiveStreamStepProviderMetadata(activeStreamId)
        : undefined;
      const liveUsage =
        rawContextUsage && model
          ? createDisplayUsage(rawContextUsage, model, rawStepProviderMetadata)
          : undefined;

      const rawCumulativeUsage = activeStreamId
        ? aggregator.getActiveStreamCumulativeUsage(activeStreamId)
        : undefined;
      const rawCumulativeProviderMetadata = activeStreamId
        ? aggregator.getActiveStreamCumulativeProviderMetadata(activeStreamId)
        : undefined;
      const liveCostUsage =
        rawCumulativeUsage && model
          ? createDisplayUsage(rawCumulativeUsage, model, rawCumulativeProviderMetadata)
          : undefined;

      return { sessionTotal, lastRequest, lastContextUsage, totalTokens, liveUsage, liveCostUsage };
    });
  }

  /**
   * Get consumer breakdown (may be calculating).
   * Triggers lazy calculation if workspace is caught-up but no data exists.
   *
   * Architecture: Lazy trigger runs on EVERY access (outside MapStore.get())
   * so workspace switches trigger calculation even if MapStore has cached result.
   */
  getWorkspaceConsumers(workspaceId: string): WorkspaceConsumersState {
    const aggregator = this.aggregators.get(workspaceId);
    const isCaughtUp = this.chatTransientState.get(workspaceId)?.caughtUp ?? false;

    // Lazy trigger check (runs on EVERY access, not just when MapStore recomputes)
    const cached = this.consumerManager.getCachedState(workspaceId);
    const isPending = this.consumerManager.isPending(workspaceId);

    if (!cached && !isPending && isCaughtUp) {
      if (aggregator && aggregator.getAllMessages().length > 0) {
        // Defer scheduling to avoid setState-during-render warning
        // queueMicrotask ensures this runs after current render completes
        queueMicrotask(() => {
          this.consumerManager.scheduleCalculation(workspaceId, aggregator);
        });
      }
    }

    // Return state (MapStore handles subscriptions, delegates to manager for actual state)
    return this.consumersStore.get(workspaceId, () => {
      return this.consumerManager.getStateSync(workspaceId);
    });
  }

  /**
   * Subscribe to usage store changes for a specific workspace.
   */
  subscribeUsage(workspaceId: string, listener: () => void): () => void {
    return this.usageStore.subscribeKey(workspaceId, listener);
  }

  /**
   * Subscribe to backend timing stats snapshots for a specific workspace.
   */
  subscribeStats(workspaceId: string, listener: () => void): () => void {
    return this.statsStore.subscribeKey(workspaceId, listener);
  }

  /**
   * Subscribe to consumer store changes for a specific workspace.
   */
  subscribeConsumers(workspaceId: string, listener: () => void): () => void {
    return this.consumersStore.subscribeKey(workspaceId, listener);
  }

  /**
   * Update usage and schedule consumer calculation after stream completion.
   *
   * CRITICAL ORDERING: This must be called AFTER the aggregator updates its messages.
   * If called before, the UI will re-render and read stale data from the aggregator,
   * causing a race condition where usage appears empty until refresh.
   *
   * Handles both:
   * - Instant usage display (from API metadata) - only if usage present
   * - Async consumer breakdown (tokenization via Web Worker) - normally scheduled,
   *   but skipped during history replay to avoid O(N) scheduling overhead
   */
  private finalizeUsageStats(
    workspaceId: string,
    metadata?: { usage?: LanguageModelV2Usage }
  ): void {
    // During history replay: only bump usage, skip scheduling (caught-up schedules once at end)
    if (this.chatTransientState.get(workspaceId)?.replayingHistory) {
      if (metadata?.usage) {
        this.usageStore.bump(workspaceId);
      }
      return;
    }

    // Normal real-time path: always bump usage.
    //
    // Even if total usage is missing (e.g. provider doesn't return it or it timed out),
    // we still need to recompute usage snapshots to:
    // - Clear liveUsage once the active stream ends
    // - Pick up lastContextUsage changes from merged message metadata
    this.usageStore.bump(workspaceId);

    // Always schedule consumer calculation (tool calls, text, etc. need tokenization)
    // Even streams without usage metadata need token counts recalculated
    const aggregator = this.aggregators.get(workspaceId);
    if (aggregator) {
      this.consumerManager.scheduleCalculation(workspaceId, aggregator);
    }
  }

  private sleepWithAbort(timeoutMs: number, signal: AbortSignal): Promise<void> {
    return new Promise((resolve) => {
      if (signal.aborted) {
        resolve();
        return;
      }

      const timeout = setTimeout(() => {
        resolve();
      }, timeoutMs);

      signal.addEventListener(
        "abort",
        () => {
          clearTimeout(timeout);
          resolve();
        },
        { once: true }
      );
    });
  }

  private isWorkspaceSubscribed(workspaceId: string): boolean {
    return this.ipcUnsubscribers.has(workspaceId);
  }

  private async waitForClient(signal: AbortSignal): Promise<RouterClient<AppRouter> | null> {
    while (!signal.aborted) {
      if (this.client) {
        return this.client;
      }

      // Wait for a client to be attached (e.g., initial connect or reconnect).
      await this.sleepWithAbort(ON_CHAT_RETRY_BASE_MS, signal);
    }

    return null;
  }

  /**
   * Reset derived UI state for a workspace so a fresh onChat replay can rebuild it.
   *
   * This is used when an onChat subscription ends unexpectedly (MessagePort/WebSocket hiccup).
   * Without clearing, replayed history would be merged into stale state (loadHistoricalMessages
   * only adds/overwrites, it doesn't delete messages that disappeared due to compaction/truncation).
   */
  private resetChatStateForReplay(workspaceId: string): void {
    const aggregator = this.aggregators.get(workspaceId);
    if (!aggregator) {
      return;
    }

    // Clear any pending UI bumps from deltas - we're about to rebuild the message list.
    this.cancelPendingIdleBump(workspaceId);

    aggregator.clear();

    // Reset per-workspace transient state so the next replay rebuilds from the backend source of truth.
    this.chatTransientState.set(workspaceId, createInitialChatTransientState());

    this.states.bump(workspaceId);
    this.checkAndBumpRecencyIfChanged();
  }

  /**
   * Subscribe to workspace chat events (history replay + live streaming).
   * Retries on unexpected iterator termination to avoid requiring a full app restart.
   */
  private async runOnChatSubscription(workspaceId: string, signal: AbortSignal): Promise<void> {
    let attempt = 0;

    while (!signal.aborted) {
      const client = this.client ?? (await this.waitForClient(signal));
      if (!client || signal.aborted) {
        return;
      }

      try {
        const iterator = await client.workspace.onChat({ workspaceId }, { signal });

        for await (const data of iterator) {
          if (signal.aborted) {
            return;
          }

          // Connection is alive again - don't carry old backoff into the next failure.
          attempt = 0;

          queueMicrotask(() => {
            this.handleChatMessage(workspaceId, data);
          });
        }

        // Iterator ended without an abort - treat as unexpected and retry.
        if (signal.aborted) {
          return;
        }

        console.warn(
          `[WorkspaceStore] onChat subscription ended unexpectedly for ${workspaceId}; retrying...`
        );
      } catch (error) {
        // Suppress errors when subscription was intentionally cleaned up
        if (signal.aborted) {
          return;
        }

        // EVENT_ITERATOR_VALIDATION_FAILED can happen when:
        // 1. Schema validation fails (event doesn't match WorkspaceChatMessageSchema)
        // 2. Workspace was removed on server side (iterator ends with error)
        // 3. Connection dropped (WebSocket/MessagePort error)
        if (isIteratorValidationFailed(error)) {
          // Only suppress if workspace no longer exists (was removed during the race)
          if (!this.isWorkspaceSubscribed(workspaceId)) {
            return;
          }
          // Log with detailed validation info for debugging schema mismatches
          console.error(
            `[WorkspaceStore] Event validation failed for ${workspaceId}: ${formatValidationError(error)}`
          );
        } else {
          console.error(`[WorkspaceStore] Error in onChat subscription for ${workspaceId}:`, error);
        }
      }

      const delayMs = calculateOnChatBackoffMs(attempt);
      attempt++;

      await this.sleepWithAbort(delayMs, signal);
      if (signal.aborted) {
        return;
      }

      this.resetChatStateForReplay(workspaceId);
    }
  }

  /**
   * Add a workspace and subscribe to its IPC events.
   */
  addWorkspace(metadata: FrontendWorkspaceMetadata): void {
    const workspaceId = metadata.id;

    // Skip if already subscribed
    if (this.ipcUnsubscribers.has(workspaceId)) {
      return;
    }

    // Store metadata for name lookup
    this.workspaceMetadata.set(workspaceId, metadata);

    // Backend guarantees createdAt via config.ts - this should never be undefined
    assert(
      metadata.createdAt,
      `Workspace ${workspaceId} missing createdAt - backend contract violated`
    );

    const aggregator = this.getOrCreateAggregator(
      workspaceId,
      metadata.createdAt,
      metadata.unarchivedAt
    );

    // Initialize recency cache and bump derived store immediately
    // This ensures UI sees correct workspace order before messages load
    const initialRecency = aggregator.getRecencyTimestamp();
    if (initialRecency !== null) {
      this.recencyCache.set(workspaceId, initialRecency);
      this.derived.bump("recency");
    }

    // Initialize transient chat state
    if (!this.chatTransientState.has(workspaceId)) {
      this.chatTransientState.set(workspaceId, createInitialChatTransientState());
    }

    // Clear stale streaming state
    aggregator.clearActiveStreams();

    // Subscribe to IPC events
    // Wrap in queueMicrotask to ensure IPC events don't update during React render
    const controller = new AbortController();
    const { signal } = controller;

    this.ipcUnsubscribers.set(workspaceId, () => controller.abort());

    // Fire and forget the subscription loop (retries on errors)
    void this.runOnChatSubscription(workspaceId, signal);

    // Fetch persisted session usage (fire-and-forget)
    this.client?.workspace
      .getSessionUsage({ workspaceId })
      .then((data) => {
        if (data) {
          this.sessionUsage.set(workspaceId, data);
          this.usageStore.bump(workspaceId);
        }
      })
      .catch((error) => {
        console.warn(`Failed to fetch session usage for ${workspaceId}:`, error);
      });

    if (this.statsEnabled) {
      this.subscribeToStats(workspaceId);
    }

    if (!this.client) {
      console.warn(`[WorkspaceStore] No ORPC client available for workspace ${workspaceId}`);
    }
  }

  /**
   * Remove a workspace and clean up subscriptions.
   */
  removeWorkspace(workspaceId: string): void {
    // Clean up consumer manager state
    this.consumerManager.removeWorkspace(workspaceId);

    // Clean up idle callback to prevent stale callbacks
    this.cancelPendingIdleBump(workspaceId);

    const statsUnsubscribe = this.statsUnsubscribers.get(workspaceId);
    if (statsUnsubscribe) {
      statsUnsubscribe();
      this.statsUnsubscribers.delete(workspaceId);
    }
    // Unsubscribe from IPC
    const unsubscribe = this.ipcUnsubscribers.get(workspaceId);
    if (unsubscribe) {
      unsubscribe();
      this.ipcUnsubscribers.delete(workspaceId);
    }

    // Clean up state
    this.states.delete(workspaceId);
    this.usageStore.delete(workspaceId);
    this.consumersStore.delete(workspaceId);
    this.aggregators.delete(workspaceId);
    this.chatTransientState.delete(workspaceId);
    this.recencyCache.delete(workspaceId);
    this.previousSidebarValues.delete(workspaceId);
    this.sidebarStateCache.delete(workspaceId);
    this.sidebarStateSourceState.delete(workspaceId);
    this.workspaceCreatedAt.delete(workspaceId);
    this.workspaceStats.delete(workspaceId);
    this.statsStore.delete(workspaceId);
    this.sessionUsage.delete(workspaceId);
  }

  /**
   * Sync workspaces with metadata - add new, remove deleted.
   */
  syncWorkspaces(workspaceMetadata: Map<string, FrontendWorkspaceMetadata>): void {
    const metadataIds = new Set(Array.from(workspaceMetadata.values()).map((m) => m.id));
    const currentIds = new Set(this.ipcUnsubscribers.keys());

    // Add new workspaces
    for (const metadata of workspaceMetadata.values()) {
      if (!currentIds.has(metadata.id)) {
        this.addWorkspace(metadata);
      }
    }

    // Remove deleted workspaces
    for (const workspaceId of currentIds) {
      if (!metadataIds.has(workspaceId)) {
        this.removeWorkspace(workspaceId);
      }
    }
  }

  /**
   * Cleanup all subscriptions (call on unmount).
   */
  dispose(): void {
    // Clean up consumer manager
    this.consumerManager.dispose();

    for (const unsubscribe of this.statsUnsubscribers.values()) {
      unsubscribe();
    }
    this.statsUnsubscribers.clear();
    for (const unsubscribe of this.ipcUnsubscribers.values()) {
      unsubscribe();
    }
    this.ipcUnsubscribers.clear();
    this.states.clear();
    this.derived.clear();
    this.usageStore.clear();
    this.consumersStore.clear();
    this.aggregators.clear();
    this.chatTransientState.clear();
    this.workspaceStats.clear();
    this.statsStore.clear();
    this.sessionUsage.clear();
    this.recencyCache.clear();
    this.previousSidebarValues.clear();
    this.sidebarStateCache.clear();
    this.workspaceCreatedAt.clear();
  }

  /**
   * Subscribe to idle compaction events.
   * Callback is called when backend signals a workspace needs idle compaction.
   * Returns unsubscribe function.
   */
  onIdleCompactionNeeded(callback: (workspaceId: string) => void): () => void {
    this.idleCompactionCallbacks.add(callback);
    return () => this.idleCompactionCallbacks.delete(callback);
  }

  /**
   * Notify all listeners that a workspace needs idle compaction.
   */
  private notifyIdleCompactionNeeded(workspaceId: string): void {
    for (const callback of this.idleCompactionCallbacks) {
      try {
        callback(workspaceId);
      } catch (error) {
        console.error("Error in idle compaction callback:", error);
      }
    }
  }

  /**
   * Subscribe to file-modifying tool completions.
   * @param listener Called with workspaceId when a file-modifying tool completes
   * @param workspaceId If provided, only notify for this workspace
   */
  subscribeFileModifyingTool(
    listener: (workspaceId: string) => void,
    workspaceId?: string
  ): () => void {
    if (workspaceId) {
      // Per-workspace: wrap listener to match subscribeKey signature
      return this.fileModifyingToolSubs.subscribeKey(workspaceId, () => listener(workspaceId));
    }
    // All workspaces: subscribe to global notifications
    return this.fileModifyingToolSubs.subscribeAny(() => {
      // Notify for all workspaces that have pending changes
      for (const wsId of this.fileModifyingToolMs.keys()) {
        listener(wsId);
      }
    });
  }

  /**
   * Get when a file-modifying tool last completed for this workspace.
   * Returns undefined if no tools have completed since last clear.
   */
  getFileModifyingToolMs(workspaceId: string): number | undefined {
    return this.fileModifyingToolMs.get(workspaceId);
  }

  /**
   * Clear the file-modifying tool timestamp after ReviewPanel has consumed it.
   */
  clearFileModifyingToolMs(workspaceId: string): void {
    this.fileModifyingToolMs.delete(workspaceId);
  }

  // Private methods

  /**
   * Get or create aggregator for a workspace.
   *
   * REQUIRES: createdAt must be provided for new aggregators.
   * Backend guarantees every workspace has createdAt via config.ts.
   *
   * If aggregator already exists, createdAt is optional (it was already set during creation).
   */
  private getOrCreateAggregator(
    workspaceId: string,
    createdAt: string,
    unarchivedAt?: string
  ): StreamingMessageAggregator {
    if (!this.aggregators.has(workspaceId)) {
      // Create new aggregator with required createdAt and workspaceId for localStorage persistence
      this.aggregators.set(
        workspaceId,
        new StreamingMessageAggregator(createdAt, workspaceId, unarchivedAt)
      );
      this.workspaceCreatedAt.set(workspaceId, createdAt);
    } else if (unarchivedAt) {
      // Update unarchivedAt on existing aggregator (e.g., after restore from archive)
      this.aggregators.get(workspaceId)!.setUnarchivedAt(unarchivedAt);
    }

    return this.aggregators.get(workspaceId)!;
  }

  /**
   * Check if data is a buffered event type by checking the handler map.
   * This ensures isStreamEvent() and processStreamEvent() can never fall out of sync.
   */
  private isBufferedEvent(data: WorkspaceChatMessage): boolean {
    return "type" in data && data.type in this.bufferedEventHandlers;
  }

  private handleChatMessage(workspaceId: string, data: WorkspaceChatMessage): void {
    // Aggregator must exist - IPC subscription happens in addWorkspace()
    const aggregator = this.assertGet(workspaceId);

    const transient = this.assertChatTransientState(workspaceId);

    if (isCaughtUpMessage(data)) {
      // Check if there's an active stream in buffered events (reconnection scenario)
      const pendingEvents = transient.pendingStreamEvents;
      const hasActiveStream = pendingEvents.some(
        (event) => "type" in event && event.type === "stream-start"
      );

      // Load historical messages first
      if (transient.historicalMessages.length > 0) {
        aggregator.loadHistoricalMessages(transient.historicalMessages, hasActiveStream);
        transient.historicalMessages.length = 0;
      }

      // Mark that we're replaying buffered history (prevents O(N) scheduling)
      transient.replayingHistory = true;

      // Process buffered stream events now that history is loaded
      for (const event of pendingEvents) {
        this.processStreamEvent(workspaceId, aggregator, event);
      }
      pendingEvents.length = 0;

      // Done replaying buffered events
      transient.replayingHistory = false;

      // Mark as caught up
      transient.caughtUp = true;
      this.states.bump(workspaceId);
      this.checkAndBumpRecencyIfChanged(); // Messages loaded, update recency

      // Bump usage after loading history
      this.usageStore.bump(workspaceId);

      // Schedule consumer calculation once after all buffered events processed
      if (aggregator.getAllMessages().length > 0) {
        this.consumerManager.scheduleCalculation(workspaceId, aggregator);
      }

      return;
    }

    // Handle idle-compaction-needed event (workspace became eligible while connected)
    if ("type" in data && data.type === "idle-compaction-needed") {
      this.notifyIdleCompactionNeeded(workspaceId);
      return;
    }

    // OPTIMIZATION: Buffer stream events until caught-up to reduce excess re-renders
    // When first subscribing to a workspace, we receive:
    // 1. Historical messages from chat.jsonl (potentially hundreds of messages)
    // 2. Partial stream state (if stream was interrupted)
    // 3. Active stream events (if currently streaming)
    //
    // Without buffering, each event would trigger a separate re-render as messages
    // arrive one-by-one over IPC. By buffering until "caught-up", we:
    // - Load all historical messages in one batch (O(1) render instead of O(N))
    // - Replay buffered stream events after history is loaded
    // - Provide correct context for stream continuation (history is complete)
    //
    // This is especially important for workspaces with long histories (100+ messages),
    // where unbuffered rendering would cause visible lag and UI stutter.
    if (!transient.caughtUp && this.isBufferedEvent(data)) {
      transient.pendingStreamEvents.push(data);
      return;
    }

    // Process event immediately (already caught up or not a stream event)
    this.processStreamEvent(workspaceId, aggregator, data);
  }

  private processStreamEvent(
    workspaceId: string,
    aggregator: StreamingMessageAggregator,
    data: WorkspaceChatMessage
  ): void {
    // Handle non-buffered special events first
    if (isStreamError(data)) {
      aggregator.handleStreamError(data);

      // Increment retry attempt counter when stream fails
      // This handles auth errors that happen AFTER stream-start
      updatePersistedState(
        getRetryStateKey(workspaceId),
        (prev) => {
          const newAttempt = prev.attempt + 1;
          console.debug(
            `[retry] ${workspaceId} stream-error: incrementing attempt ${prev.attempt}  ${newAttempt}`
          );
          return {
            attempt: newAttempt,
            retryStartTime: Date.now(),
          };
        },
        { attempt: 0, retryStartTime: Date.now() }
      );

      this.states.bump(workspaceId);
      this.dispatchResumeCheck(workspaceId);
      return;
    }

    if (isDeleteMessage(data)) {
      aggregator.handleDeleteMessage(data);
      this.cleanupStaleLiveBashOutput(workspaceId, aggregator);
      this.states.bump(workspaceId);
      this.checkAndBumpRecencyIfChanged();
      this.usageStore.bump(workspaceId);
      this.consumerManager.scheduleCalculation(workspaceId, aggregator);
      return;
    }

    if (isBashOutputEvent(data)) {
      if (data.text.length === 0) return;

      const transient = this.assertChatTransientState(workspaceId);

      const prev = transient.liveBashOutput.get(data.toolCallId);
      const next = appendLiveBashOutputChunk(
        prev,
        { text: data.text, isError: data.isError },
        BASH_TRUNCATE_MAX_TOTAL_BYTES
      );

      transient.liveBashOutput.set(data.toolCallId, next);

      // High-frequency: throttle UI updates like other delta-style events.
      this.scheduleIdleStateBump(workspaceId);
      return;
    }

    // Try buffered event handlers (single source of truth)
    if ("type" in data && data.type in this.bufferedEventHandlers) {
      this.bufferedEventHandlers[data.type](workspaceId, aggregator, data);
      return;
    }

    // Regular messages (MuxMessage without type field)
    if (isMuxMessage(data)) {
      const transient = this.assertChatTransientState(workspaceId);

      if (!transient.caughtUp) {
        // Buffer historical MuxMessages
        transient.historicalMessages.push(data);
      } else {
        // Process live events immediately (after history loaded)
        aggregator.handleMessage(data);
        this.states.bump(workspaceId);
        this.usageStore.bump(workspaceId);
        this.checkAndBumpRecencyIfChanged();
      }
      return;
    }

    // If we reach here, unknown message type - log for debugging
    if ("role" in data || "type" in data) {
      console.error("[WorkspaceStore] Unknown message type - not processed", {
        workspaceId,
        hasRole: "role" in data,
        hasType: "type" in data,
        type: "type" in data ? (data as { type: string }).type : undefined,
        role: "role" in data ? (data as { role: string }).role : undefined,
      });
    }
    // Note: Messages without role/type are silently ignored (expected for some IPC events)
  }
}

// ============================================================================
// React Integration with useSyncExternalStore
// ============================================================================

// Singleton store instance
let storeInstance: WorkspaceStore | null = null;

/**
 * Get or create the singleton WorkspaceStore instance.
 */
function getStoreInstance(): WorkspaceStore {
  storeInstance ??= new WorkspaceStore(() => {
    // Model tracking callback - can hook into other systems if needed
  });
  return storeInstance;
}

/**
 * Direct access to the singleton store instance.
 * Use this for non-hook subscriptions (e.g., in useEffect callbacks).
 */
export const workspaceStore = {
  onIdleCompactionNeeded: (callback: (workspaceId: string) => void) =>
    getStoreInstance().onIdleCompactionNeeded(callback),
  subscribeFileModifyingTool: (listener: (workspaceId: string) => void, workspaceId?: string) =>
    getStoreInstance().subscribeFileModifyingTool(listener, workspaceId),
  getFileModifyingToolMs: (workspaceId: string) =>
    getStoreInstance().getFileModifyingToolMs(workspaceId),
  clearFileModifyingToolMs: (workspaceId: string) =>
    getStoreInstance().clearFileModifyingToolMs(workspaceId),
};

/**
 * Hook to get state for a specific workspace.
 * Only re-renders when THIS workspace's state changes.
 *
 * Uses per-key subscription for surgical updates - only notified when
 * this specific workspace's state changes.
 */
export function useWorkspaceState(workspaceId: string): WorkspaceState {
  const store = getStoreInstance();

  return useSyncExternalStore(
    (listener) => store.subscribeKey(workspaceId, listener),
    () => store.getWorkspaceState(workspaceId)
  );
}

/**
 * Hook to access the raw store for imperative operations.
 */
export function useWorkspaceStoreRaw(): WorkspaceStore {
  return getStoreInstance();
}

/**
 * Hook to get workspace recency timestamps.
 * Subscribes to derived state since recency is updated via derived.bump("recency").
 */
export function useWorkspaceRecency(): Record<string, number> {
  const store = getStoreInstance();

  return useSyncExternalStore(store.subscribeDerived, () => store.getWorkspaceRecency());
}

/**
 * Hook to get sidebar-specific state for a workspace.
 * Only re-renders when sidebar-relevant fields change (not on every message).
 *
 * getWorkspaceSidebarState returns cached references, so this won't cause
 * unnecessary re-renders even when the subscription fires.
 */
export function useWorkspaceSidebarState(workspaceId: string): WorkspaceSidebarState {
  const store = getStoreInstance();

  return useSyncExternalStore(
    (listener) => store.subscribeKey(workspaceId, listener),
    () => store.getWorkspaceSidebarState(workspaceId)
  );
}

/**
 * Hook to get UI-only live stdout/stderr for a running bash tool call.
 */
export function useBashToolLiveOutput(
  workspaceId: string | undefined,
  toolCallId: string | undefined
): LiveBashOutputView | null {
  const store = getStoreInstance();

  return useSyncExternalStore(
    (listener) => {
      if (!workspaceId) return () => undefined;
      return store.subscribeKey(workspaceId, listener);
    },
    () => {
      if (!workspaceId || !toolCallId) return null;
      return store.getBashToolLiveOutput(workspaceId, toolCallId);
    }
  );
}

/**
 * Hook to get an aggregator for a workspace.
 */
export function useWorkspaceAggregator(
  workspaceId: string
): StreamingMessageAggregator | undefined {
  const store = useWorkspaceStoreRaw();
  return store.getAggregator(workspaceId);
}

/**
 * Add an ephemeral message to a workspace and trigger a re-render.
 * Used for displaying frontend-only messages like /plan output.
 */
export function addEphemeralMessage(workspaceId: string, message: MuxMessage): void {
  const store = getStoreInstance();
  const aggregator = store.getAggregator(workspaceId);
  if (aggregator) {
    aggregator.addMessage(message);
    store.bumpState(workspaceId);
  }
}

/**
 * Remove an ephemeral message from a workspace and trigger a re-render.
 * Used for dismissing frontend-only messages like /plan output.
 */
export function removeEphemeralMessage(workspaceId: string, messageId: string): void {
  const store = getStoreInstance();
  const aggregator = store.getAggregator(workspaceId);
  if (aggregator) {
    aggregator.removeMessage(messageId);
    store.bumpState(workspaceId);
  }
}

/**
 * Hook for usage metadata (instant, no tokenization).
 * Updates immediately when usage metadata arrives from API responses.
 */
export function useWorkspaceUsage(workspaceId: string): WorkspaceUsageState {
  const store = getStoreInstance();
  return useSyncExternalStore(
    (listener) => store.subscribeUsage(workspaceId, listener),
    () => store.getWorkspaceUsage(workspaceId)
  );
}

/**
 * Hook for backend timing stats snapshots.
 */
export function useWorkspaceStatsSnapshot(workspaceId: string): WorkspaceStatsSnapshot | null {
  const store = getStoreInstance();
  return useSyncExternalStore(
    (listener) => store.subscribeStats(workspaceId, listener),
    () => store.getWorkspaceStatsSnapshot(workspaceId)
  );
}

/**
 * Hook for consumer breakdown (lazy, with tokenization).
 * Updates after async Web Worker calculation completes.
 */
export function useWorkspaceConsumers(workspaceId: string): WorkspaceConsumersState {
  const store = getStoreInstance();
  return useSyncExternalStore(
    (listener) => store.subscribeConsumers(workspaceId, listener),
    () => store.getWorkspaceConsumers(workspaceId)
  );
}
