name: Nightly Terminal-Bench

on:
  schedule:
    # Run full benchmark suite every night at midnight UTC
    - cron: "0 0 * * *"
  workflow_dispatch:
    inputs:
      models:
        description: 'Models to test (comma-separated, or "all" for opus + gpt-5.2-codex + gpt-5.2 + google/gemini-3-pro-preview + google/gemini-3-flash-preview)'
        required: false
        default: "all"
        type: string
      experiments:
        description: "Experiments to enable (comma-separated)"
        required: false
        type: string

jobs:
  # Smoke test: run chess-best-move task first to catch broken agent setup
  # If this fails, skip the full suite to save time and API costs
  smoke-test:
    name: Smoke test (chess-best-move)
    uses: ./.github/workflows/terminal-bench.yml
    with:
      model_name: "anthropic/claude-sonnet-4-5"
      thinking_level: "high"
      dataset: "terminal-bench@2.0"
      concurrency: "1"
      env: "daytona"
      task_names: "chess-best-move"
      experiments: ${{ inputs.experiments }}
    secrets: inherit # zizmor: ignore[secrets-inherit]

  # Smoke tests for Harbor SWE-style datasets (single task each).
  # These validate that mux can run inside the dataset's repo checkout (MUX_RUNTIME=local)
  # and that we target the verifier's expected working directory (MUX_PROJECT_PATH).
  swebench-verified-smoke-test:
    name: "Smoke test (swebench-verified: django__django-10097)"
    needs: smoke-test
    uses: ./.github/workflows/terminal-bench.yml
    with:
      model_name: "anthropic/claude-sonnet-4-5"
      thinking_level: "high"
      dataset: "swebench-verified@1.0"
      concurrency: "1"
      env: "daytona"
      task_names: "django__django-10097"
      mux_project_path: "/testbed"
      mux_runtime: "local"
      timeout: "3000"
      experiments: ${{ inputs.experiments }}
    secrets: inherit # zizmor: ignore[secrets-inherit]

  swe-gen-js-smoke-test:
    name: "Smoke test (swe-gen-js: biomejs__biome-7314)"
    needs: smoke-test
    uses: ./.github/workflows/terminal-bench.yml
    with:
      model_name: "anthropic/claude-sonnet-4-5"
      thinking_level: "high"
      dataset: "swe-gen-js@1.0"
      concurrency: "1"
      env: "daytona"
      task_names: "biomejs__biome-7314"
      mux_project_path: "/app/src"
      mux_runtime: "local"
      timeout: "600"
      experiments: ${{ inputs.experiments }}
    secrets: inherit # zizmor: ignore[secrets-inherit]

  aider-polyglot-smoke-test:
    name: "Smoke test (aider-polyglot: polyglot_cpp_all-your-base)"
    needs: smoke-test
    uses: ./.github/workflows/terminal-bench.yml
    with:
      model_name: "anthropic/claude-sonnet-4-5"
      thinking_level: "high"
      dataset: "aider-polyglot@1.0"
      concurrency: "1"
      env: "daytona"
      task_names: "polyglot_cpp_all-your-base"
      mux_project_path: "/app"
      mux_runtime: "local"
      timeout: "1800"
      experiments: ${{ inputs.experiments }}
    secrets: inherit # zizmor: ignore[secrets-inherit]

  determine-models:
    name: Determine models to test
    needs: smoke-test
    runs-on: ubuntu-latest
    outputs:
      models: ${{ steps.set-models.outputs.models }}
    steps:
      - name: Set models matrix
        id: set-models
        env:
          INPUT_MODELS: ${{ inputs.models }}
        run: |
          if [ "$INPUT_MODELS" = "all" ] || [ -z "$INPUT_MODELS" ]; then
            echo 'models=["anthropic/claude-opus-4-5","openai/gpt-5.2-codex","openai/gpt-5.2","google/gemini-3-pro-preview","google/gemini-3-flash-preview"]' >> "$GITHUB_OUTPUT"
          else
            # Convert comma-separated to JSON array
            models_json=$(echo "$INPUT_MODELS" | jq -R -s -c 'split(",") | map(gsub("^\\s+|\\s+$"; ""))')
            echo "models=$models_json" >> "$GITHUB_OUTPUT"
          fi

  benchmark:
    name: ${{ matrix.model }}
    needs: [smoke-test, determine-models]
    strategy:
      matrix:
        model: ${{ fromJSON(needs.determine-models.outputs.models) }}
      fail-fast: false
      max-parallel: 1  # Run models sequentially to stay within Daytona's 25-sandbox limit
    uses: ./.github/workflows/terminal-bench.yml
    with:
      model_name: ${{ matrix.model }}
      # gpt-5 class models use xhigh thinking, others use high
      thinking_level: ${{ contains(matrix.model, 'gpt-5') && 'xhigh' || 'high' }}
      dataset: "terminal-bench@2.0"
      concurrency: "48"
      env: "daytona"
      experiments: ${{ inputs.experiments }}
    secrets: inherit # zizmor: ignore[secrets-inherit]
